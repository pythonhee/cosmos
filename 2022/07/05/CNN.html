<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>mnist ë°ì´í„°ë¥¼ ì´ìš©í•œ multi_layers í•™ìŠµ | soheeğŸŒ¸</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="mnist ë°ì´í„°ë¥¼ ì´ìš©í•œ multi_layers í•™ìŠµ" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://pythonhee.github.io/cosmos/2022/07/05/CNN.html" />
<meta property="og:url" content="https://pythonhee.github.io/cosmos/2022/07/05/CNN.html" />
<meta property="og:site_name" content="soheeğŸŒ¸" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-05T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="mnist ë°ì´í„°ë¥¼ ì´ìš©í•œ multi_layers í•™ìŠµ" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-07-05T00:00:00-05:00","datePublished":"2022-07-05T00:00:00-05:00","description":"An easy to use blogging platform with support for Jupyter Notebooks.","headline":"mnist ë°ì´í„°ë¥¼ ì´ìš©í•œ multi_layers í•™ìŠµ","mainEntityOfPage":{"@type":"WebPage","@id":"https://pythonhee.github.io/cosmos/2022/07/05/CNN.html"},"url":"https://pythonhee.github.io/cosmos/2022/07/05/CNN.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/cosmos/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://pythonhee.github.io/cosmos/feed.xml" title="soheeğŸŒ¸" /><link rel="shortcut icon" type="image/x-icon" href="/cosmos/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/cosmos/">soheeğŸŒ¸</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/cosmos/about/">About Me</a><a class="page-link" href="/cosmos/search/">Search</a><a class="page-link" href="/cosmos/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">mnist ë°ì´í„°ë¥¼ ì´ìš©í•œ multi_layers í•™ìŠµ</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-07-05T00:00:00-05:00" itemprop="datePublished">
        Jul 5, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/pythonhee/cosmos/tree/master/_notebooks/2022-07-05-CNN.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/cosmos/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/pythonhee/cosmos/master?filepath=_notebooks%2F2022-07-05-CNN.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/cosmos/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/pythonhee/cosmos/blob/master/_notebooks/2022-07-05-CNN.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/cosmos/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fpythonhee%2Fcosmos%2Fblob%2Fmaster%2F_notebooks%2F2022-07-05-CNN.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/cosmos/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#12_1_single_layer">12_1_single_layer </a></li>
<li class="toc-entry toc-h2"><a href="#12_2_multi_layers">12_2_multi_layers </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-07-05-CNN.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="12_1_single_layer">
<a class="anchor" href="#12_1_single_layer" aria-hidden="true"><span class="octicon octicon-link"></span></a>12_1_single_layer<a class="anchor-link" href="#12_1_single_layer"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Dense í•¨ìˆ˜ì™€ ì—¬ëŸ¬ê°œì˜ ì´ˆê¸°í™” ê°’ ì •ì˜í•˜ê¸°</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

  <span class="k">return</span> <span class="n">activations</span><span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span> <span class="k">if</span> <span class="n">activations</span> <span class="k">else</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_weight_normal</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
  <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">]))</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">n_output</span><span class="p">]))</span>

  <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">make_weight_glorot</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
  <span class="n">glorot</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">GlorotUniform</span><span class="p">()</span>
  <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">glorot</span><span class="p">([</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">]))</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_output</span><span class="p">]))</span>

  <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>

<span class="k">def</span> <span class="nf">make_weight_he</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">):</span>
  <span class="n">he</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">HeUniform</span><span class="p">()</span>
  <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">he</span><span class="p">([</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_output</span><span class="p">]))</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_output</span><span class="p">]))</span>

  <span class="k">return</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>mnist_single_layer í•¨ìˆ˜ ìƒì„±</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">mnist_single_layer</span><span class="p">():</span>
  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000, 28, 28) (10000, 28, 28) </span>
  <span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000,) (10000,) =&gt; yê°’ì´ 1ì°¨ì›ì´ë¼ëŠ” ëœ»ì€ sparse ë²„ì „ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ëŠ” ì˜ë¯¸</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>   <span class="c1"># 0, 255</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># xë°ì´í„°ë¥¼ 0~1 ê°’ìœ¼ë¡œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ì‘ì—….</span>

  <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>                              <span class="c1"># n_output ê°’</span>

  <span class="c1"># w, b = make_weight_normal(x_train.shape[-1], n_classes)</span>
  <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">make_weight_glorot</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_classes</span><span class="p">)</span>
  <span class="c1"># w, b = make_weight_he(x_train.shape[-1], n_classes)</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># SGD, RMSprop ì¨ë„ ê´œì°®ìŒ ì—¬ëŸ¬ ê°œ ì¨ê°€ë©´ì„œ ì„±ëŠ¥ ë¹„êµ!</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
      <span class="n">hx</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

      <span class="n">scce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">scce</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>

    <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
  <span class="nb">print</span><span class="p">()</span>  

  <span class="n">p</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>                <span class="c1">#(10000, 10)</span>

  <span class="n">p_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="n">p_arg</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'acc:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_arg</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">mnist_single_layer</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(60000, 28, 28) (10000, 28, 28)
(60000,) (10000,)
0 255
0 2.4037037
1 1.9596609
2 1.599312
3 1.3130828
4 1.1049172
5 0.95262057
6 0.83855027
7 0.7554665
8 0.69375753
9 0.64428
10 0.60332835
11 0.5701764
12 0.54368937
13 0.5217784
14 0.502841
15 0.48651809
16 0.47281685
17 0.4612233
18 0.45088997
19 0.44128928
20 0.43242112
21 0.42447037
22 0.41741672
23 0.41099578
24 0.4049556
25 0.39925858
26 0.39401338
27 0.3892681
28 0.38491824
29 0.38080114
30 0.376837
31 0.37305978
32 0.36953098
33 0.36624712
34 0.36313674
35 0.36013457
36 0.35723847
37 0.35448992
38 0.35190997
39 0.34946993
40 0.34712353
41 0.34485543
42 0.34268677
43 0.34063777
44 0.33869678
45 0.33683166
46 0.33502424
47 0.33328217
48 0.33161727
49 0.33002266
50 0.32847792
51 0.32697153
52 0.32550958
53 0.32410192
54 0.32274655
55 0.32143202
56 0.32015175
57 0.3189091
58 0.317709
59 0.31654832
60 0.31541887
61 0.3143168
62 0.3132445
63 0.31220457
64 0.31119463
65 0.31020984
66 0.30924878
67 0.30831352
68 0.30740508
69 0.30652076
70 0.30565703
71 0.3048132
72 0.30399042
73 0.3031882
74 0.30240428
75 0.30163667
76 0.3008854
77 0.3001511
78 0.29943293
79 0.2987289
80 0.2980381
81 0.29736075
82 0.29669678
83 0.29604524
84 0.29540515
85 0.29477626
86 0.2941588
87 0.2935524
88 0.29295632
89 0.29236993
90 0.2917933
91 0.29122633
92 0.2906685
93 0.2901193
94 0.28957856
95 0.28904623
96 0.28852212
97 0.28800583
98 0.2874971
99 0.28699583

(10000, 10)
[7 2 1 ... 4 5 6]
acc: 0.9208
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>mini_batch ì‚¬ìš©í•´ ìƒì„±</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">mnist_single_layer_mini_batch</span><span class="p">():</span>
  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000, 28, 28) (10000, 28, 28) </span>
  <span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000,) (10000,) =&gt; yê°’ì´ 1ì°¨ì›ì´ë¼ëŠ” ëœ»ì€ sparse ë²„ì „ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ëŠ” ì˜ë¯¸</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>   <span class="c1"># 0, 255</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># xë°ì´í„°ë¥¼ 0~1 ê°’ìœ¼ë¡œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ì‘ì—….</span>

  <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>                              <span class="c1"># n_output ê°’</span>

  <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_classes</span><span class="p">)</span>

  <span class="c1"># w, b = make_weight_glorot(x_train.shape[-1], n_classes)</span>
  <span class="c1"># acc: 0.4583</span>
  
  <span class="c1"># w, b = make_weight_he(x_train.shape[-1], n_classes)</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># SGD, RMSprop ì¨ë„ ê´œì°®ìŒ ì—¬ëŸ¬ ê°œ ì¨ê°€ë©´ì„œ ì„±ëŠ¥ ë¹„êµ!</span>

  <span class="n">epoch</span> <span class="o">=</span> <span class="mi">10</span>                               <span class="c1"># 60000ë°ì´í„°ë¥¼ 10íšŒ ë°˜ë³µí•œë‹¤ëŠ” ì˜ë¯¸ </span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="n">n_literation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>   <span class="c1"># 600</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_literation</span><span class="p">):</span>              <span class="c1"># 6000ë²ˆì´ë‚˜ ë°˜ë³µ í™•ë¥ ì´ up</span>
      <span class="n">n1</span> <span class="o">=</span> <span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span>
      <span class="n">n2</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">*</span> <span class="n">batch_size</span>

      <span class="n">xx</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>
      <span class="n">yy</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">hx</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

        <span class="n">scce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">scce</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

      <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">total</span> <span class="o">/</span> <span class="n">n_literation</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>  

  <span class="n">p</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>                <span class="c1">#(10000, 10)</span>

  <span class="n">p_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="n">p_arg</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'acc:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_arg</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">mnist_single_layer_mini_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
(60000, 28, 28) (10000, 28, 28)
(60000,) (10000,)
0 255
0 0.31139886550294854
1 0.1945932127473255
2 0.17942959094420075
3 0.17137116949539632
4 0.1662351022940129
5 0.16266893739035973
6 0.16009065205580555
7 0.15819382834791515
8 0.15678756201523356
9 0.1557471169391647

(10000, 10)
[7 2 1 ... 4 5 6]
acc: 0.899
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="12_2_multi_layers">
<a class="anchor" href="#12_2_multi_layers" aria-hidden="true"><span class="octicon octicon-link"></span></a>12_2_multi_layers<a class="anchor-link" href="#12_2_multi_layers"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>layer 3ê°œ</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">mnist_multiple_layer_mini_batch_3</span><span class="p">():</span>
  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000, 28, 28) (10000, 28, 28) </span>
  <span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000,) (10000,) =&gt; yê°’ì´ 1ì°¨ì›ì´ë¼ëŠ” ëœ»ì€ sparse ë²„ì „ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ëŠ” ì˜ë¯¸</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>   <span class="c1"># 0, 255</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># xë°ì´í„°ë¥¼ 0~1 ê°’ìœ¼ë¡œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ì‘ì—….</span>

  <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>                              <span class="c1"># n_output ê°’</span>

  <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
  <span class="c1"># acc: 0.9423</span>

  <span class="c1"># w1, b1 = make_weight_glorot(x_train.shape[-1], 256)</span>
  <span class="c1"># w2, b2 = make_weight_glorot(256, 256)</span>
  <span class="c1"># w3, b3 = make_weight_glorot(256, n_classes)</span>
  <span class="c1"># ê²°ê³¼ :</span>

  <span class="c1"># w1, b1 = make_weight_he(x_train.shape[-1], 256)</span>
  <span class="c1"># w2, b2 = make_weight_he(256, 256)</span>
  <span class="c1"># w3, b3 = make_weight_he(256, n_classes)</span>
  <span class="c1"># ê²°ê³¼ :</span>


  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># SGD, RMSprop ì¨ë„ ê´œì°®ìŒ ì—¬ëŸ¬ ê°œ ì¨ê°€ë©´ì„œ ì„±ëŠ¥ ë¹„êµ!</span>

  <span class="n">epoch</span> <span class="o">=</span> <span class="mi">10</span>                               <span class="c1"># 60000ë°ì´í„°ë¥¼ 10íšŒ ë°˜ë³µí•œë‹¤ëŠ” ì˜ë¯¸ </span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="n">n_literation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>   <span class="c1"># 600</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_literation</span><span class="p">):</span>              <span class="c1"># 6000ë²ˆì´ë‚˜ ë°˜ë³µ í™•ë¥ ì´ up</span>
      <span class="n">n1</span> <span class="o">=</span> <span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span>
      <span class="n">n2</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">*</span> <span class="n">batch_size</span>

      <span class="n">xx</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>
      <span class="n">yy</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">hx</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

  <span class="c1"># layerë¼ë¦¬ ì—°ê²°í•  ë•Œ activationì€ non-linearí•´ì•¼í•œë‹¤. </span>
  <span class="c1"># sigmoid ,  softmax ëŠ” ì˜ˆì¸¡ x = &gt; ë§ˆì§€ë§‰ì—ë§Œ í™•ë¥ ë¡œ ë³€ê²½í•˜ëŠ” sigmoid, softmax ì‚¬ìš©</span>
  <span class="c1"># relu ëŠ” 0ë³´ë‹¤ ì‘ì€ ê°’ì€ 0ìœ¼ë¡œ, 0ë³´ë‹¤ í° ê°’ì€ ê·¸ëŒ€ë¡œ ë‚˜íƒ€ëƒ„ 0ë³´ë‹¤ ì‘ì€ ê°’ì´ ë§ì€ ë°ì´í„°ëŠ” ì‚¬ìš©í•˜ê¸° ì–´ë ¤ì›€.</span>

        <span class="n">scce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">scce</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

      <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">])</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">total</span> <span class="o">/</span> <span class="n">n_literation</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>  

  <span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>                <span class="c1">#(10000, 10)</span>

  <span class="n">p_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'acc:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_arg</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">mnist_multiple_layer_mini_batch_3</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(60000, 28, 28) (10000, 28, 28)
(60000,) (10000,)
0 255
0 1461.6672620370766
1 1.1854659057674386
2 0.3881142702441624
3 0.15620899812240774
4 0.06981539531475088
5 0.03489897323093222
6 3.321667264445374
7 0.14723950815076628
8 0.09502428941739102
9 0.06494564253681649

(10000, 10)
acc: 0.9423
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Q</code> layer 5ê°œë¡œ ëŠ˜ë ¤ ì •í™•ë„ë¥¼ êµ¬í•˜ê³  layer 3ê°œë¥¼ ì´ìš©í–ˆì„ ë•Œì™€ ë¹„êµí•˜ì‹œì˜¤</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">mnist_multiple_layer_mini_batch_5</span><span class="p">():</span>
  <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000, 28, 28) (10000, 28, 28) </span>
  <span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>        <span class="c1"># (60000,) (10000,) =&gt; yê°’ì´ 1ì°¨ì›ì´ë¼ëŠ” ëœ»ì€ sparse ë²„ì „ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ëŠ” ì˜ë¯¸</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>   <span class="c1"># 0, 255</span>

  <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># xë°ì´í„°ë¥¼ 0~1 ê°’ìœ¼ë¡œ ì •ê·œí™”ì‹œì¼œì£¼ëŠ” ì‘ì—….</span>

  <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>                              <span class="c1"># n_output ê°’</span>

  <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
  <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">w4</span><span class="p">,</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">w5</span><span class="p">,</span> <span class="n">b5</span> <span class="o">=</span> <span class="n">make_weight_normal</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
  <span class="c1"># acc: 0.8988 </span>

  <span class="c1"># w1, b1 = make_weight_glorot(x_train.shape[-1], 256)</span>
  <span class="c1"># w2, b2 = make_weight_glorot(256, 64)</span>
  <span class="c1"># w3, b3 = make_weight_glorot(64, 32)</span>
  <span class="c1"># w4, b4 = make_weight_glorot(32, 32)</span>
  <span class="c1"># w5, b5 = make_weight_glorot(32, n_classes)</span>
  <span class="c1"># ê²°ê³¼ :</span>

  <span class="c1"># w1, b1 = make_weight_he(x_train.shape[-1], 256)</span>
  <span class="c1"># w2, b2 = make_weight_he(256, 64)</span>
  <span class="c1"># w3, b3 = make_weight_he(64, 32)</span>
  <span class="c1"># w4, b4 = make_weight_he(32, 32)</span>
  <span class="c1"># w5, b5 = make_weight_he(32, n_classes)</span>
  <span class="c1"># ê²°ê³¼ :</span>


  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="c1"># SGD, RMSprop ì¨ë„ ê´œì°®ìŒ ì—¬ëŸ¬ ê°œ ì¨ê°€ë©´ì„œ ì„±ëŠ¥ ë¹„êµ!</span>

  <span class="n">epoch</span> <span class="o">=</span> <span class="mi">10</span>                               <span class="c1"># 60000ë°ì´í„°ë¥¼ 10íšŒ ë°˜ë³µí•œë‹¤ëŠ” ì˜ë¯¸ </span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
  <span class="n">n_literation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>   <span class="c1"># 600</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_literation</span><span class="p">):</span>              <span class="c1"># 6000ë²ˆì´ë‚˜ ë°˜ë³µ í™•ë¥ ì´ up</span>
      <span class="n">n1</span> <span class="o">=</span> <span class="n">j</span> <span class="o">*</span> <span class="n">batch_size</span>
      <span class="n">n2</span> <span class="o">=</span> <span class="n">n1</span> <span class="o">*</span> <span class="n">batch_size</span>

      <span class="n">xx</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>
      <span class="n">yy</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">n1</span><span class="p">:</span><span class="n">n2</span><span class="p">]</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">d3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">d4</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d3</span><span class="p">,</span> <span class="n">w4</span><span class="p">,</span> <span class="n">b4</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
        <span class="n">hx</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d4</span><span class="p">,</span> <span class="n">w5</span><span class="p">,</span> <span class="n">b5</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

        <span class="n">scce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">scce</span><span class="p">(</span><span class="n">yy</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

      <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">w4</span><span class="p">,</span> <span class="n">b4</span><span class="p">,</span> <span class="n">w5</span><span class="p">,</span> <span class="n">b5</span><span class="p">])</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="p">[</span><span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">w4</span><span class="p">,</span> <span class="n">b4</span><span class="p">,</span> <span class="n">w5</span><span class="p">,</span> <span class="n">b5</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">total</span> <span class="o">/</span> <span class="n">n_literation</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">()</span>  

  <span class="n">d1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">d2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">d3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">w3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">d4</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d3</span><span class="p">,</span> <span class="n">w4</span><span class="p">,</span> <span class="n">b4</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">d4</span><span class="p">,</span> <span class="n">w5</span><span class="p">,</span> <span class="n">b5</span><span class="p">,</span> <span class="n">activations</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>                <span class="c1">#(10000, 10)</span>

  <span class="n">p_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'acc:'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_arg</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">mnist_multiple_layer_mini_batch_5</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(60000, 28, 28) (10000, 28, 28)
(60000,) (10000,)
0 255
0 115397.61487060547
1 88.93705628871918
2 124.64481646577518
3 8.39682581782341
4 95.10231856604418
5 5.290038377592961
6 3.5611470832582564
7 8.595668331881365
8 25.354680725370223
9 1.1293716185198477

(10000, 10)
acc: 0.8988
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Q</code> normal ë²„ì „ ë§ê³  glorot, he ë²„ì „ë„ ëŒë ¤ë³´ë©´ì„œ ì •í™•ë„ë¥¼ ì¸¡ì •í•´ ë³´ì‹œì˜¤</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pythonhee/cosmos"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/cosmos/2022/07/05/CNN.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/cosmos/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/cosmos/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/cosmos/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/cosmos/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
