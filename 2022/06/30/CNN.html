<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>logistic regression í•¨ìˆ˜ ìƒì„± ë° indian í”„ë¡œì íŠ¸ | soheeğŸŒ¸</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="logistic regression í•¨ìˆ˜ ìƒì„± ë° indian í”„ë¡œì íŠ¸" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://pythonhee.github.io/cosmos/2022/06/30/CNN.html" />
<meta property="og:url" content="https://pythonhee.github.io/cosmos/2022/06/30/CNN.html" />
<meta property="og:site_name" content="soheeğŸŒ¸" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-30T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="logistic regression í•¨ìˆ˜ ìƒì„± ë° indian í”„ë¡œì íŠ¸" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-30T00:00:00-05:00","datePublished":"2022-06-30T00:00:00-05:00","description":"An easy to use blogging platform with support for Jupyter Notebooks.","headline":"logistic regression í•¨ìˆ˜ ìƒì„± ë° indian í”„ë¡œì íŠ¸","mainEntityOfPage":{"@type":"WebPage","@id":"https://pythonhee.github.io/cosmos/2022/06/30/CNN.html"},"url":"https://pythonhee.github.io/cosmos/2022/06/30/CNN.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/cosmos/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://pythonhee.github.io/cosmos/feed.xml" title="soheeğŸŒ¸" /><link rel="shortcut icon" type="image/x-icon" href="/cosmos/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/cosmos/">soheeğŸŒ¸</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/cosmos/about/">About Me</a><a class="page-link" href="/cosmos/search/">Search</a><a class="page-link" href="/cosmos/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">logistic regression í•¨ìˆ˜ ìƒì„± ë° indian í”„ë¡œì íŠ¸</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-06-30T00:00:00-05:00" itemprop="datePublished">
        Jun 30, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/pythonhee/cosmos/tree/master/_notebooks/2022-06-30-CNN.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/cosmos/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/pythonhee/cosmos/master?filepath=_notebooks%2F2022-06-30-CNN.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/cosmos/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/pythonhee/cosmos/blob/master/_notebooks/2022-06-30-CNN.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/cosmos/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fpythonhee%2Fcosmos%2Fblob%2Fmaster%2F_notebooks%2F2022-06-30-CNN.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/cosmos/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#9_1_logistic_regression">9_1_logistic_regression </a></li>
<li class="toc-entry toc-h2"><a href="#9_2_logistic_regression_indian">9_2_logistic_regression_indian </a></li>
<li class="toc-entry toc-h2"><a href="#9_3_logistic_regression_indian_split">9_3_logistic_regression_indian_split </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-06-30-CNN.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="9_1_logistic_regression">
<a class="anchor" href="#9_1_logistic_regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>9_1_logistic_regression<a class="anchor-link" href="#9_1_logistic_regression"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>sigmoid ë°°ìš°ê¸°</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">e</span> <span class="o">**</span> <span class="o">-</span><span class="n">z</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">show_sigmoid</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="s1">'ro'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">show_sigmoid</span><span class="p">()</span>      <span class="c1"># Denseê°€ ì§ì„ ì´ ì•„ë‹Œ ê³¡ì„ ìœ¼ë¡œ í‘œí˜„ë˜ì–´ ë” ìœ ì—°í•˜ê²Œ ê°’ì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆë‹¤. </span>

<span class="c1"># linear == ì§ì„  1ê°œ        =&gt; 2ê°œ ì¤‘ 1ê°œ ê³ ë¥´ê¸° </span>
<span class="c1"># multiple == ì§ì„  2ê°œì´ìƒ  =&gt; ì—¬ëŸ¬ê°œ ì¤‘ 1ê°œ ê³ ë¥´ê¸° </span>
<span class="c1"># sigmoid == ê³¡ì„  1ê°œ       =&gt; 2ê°œ ì¤‘ 1ê°œ ê³ ë¥´ê¸° </span>
<span class="c1"># softmax == ê³¡ì„  2ê°œì´ìƒ   =&gt; ì—¬ëŸ¬ê°œ ì¤‘ 1ê°œ ê³ ë¥´ê¸°</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>binary_cross_entropy() í•¨ìˆ˜ ìƒì„±</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">binary_cross_entropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span> 
  <span class="n">loss_i</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_i</span><span class="p">)</span>

<span class="c1"># mean_sqaure_error ëŒ€ì‹ ì‚¬ìš©</span>
<span class="c1"># 0ê³¼ 1ë¡œ ì´ë¤„ì–´ì ¸ sigmoidì— ì‚¬ìš©í•˜ê¸° ì¢‹ë‹¤.</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">logistic_regression</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>

  <span class="n">x</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>         <span class="c1"># í•™ìŠµì‹œê°„, ì¶œì„ì¼ìˆ˜ (6, 2)</span>
      <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
      <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span> 

  <span class="n">y</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span>               
       <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">],</span>             <span class="c1"># 0 == íƒˆë½, 1 == í†µê³¼ (6, 1)</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">1</span><span class="p">]]</span> 

  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>       <span class="c1"># y ë°ì´í„°ê°€ ë°˜ë“œì‹œ ìˆ«ìì—¬ì•¼ í•˜ê¸° ë•Œë¬¸ì— ìˆ«ìë¡œ ì§€ì •í•´ì¤€ë‹¤. </span>

  <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>   <span class="c1"># (6, 1) = (6, 2) * (2, 1)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
      <span class="n">hx</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">gradient1</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient1</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="s1">':'</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">p_flat</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p_flat</span><span class="p">)</span>

    <span class="n">p_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">p_flat</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p_bool</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_flat</span><span class="p">)</span>

    <span class="n">equals</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_bool</span> <span class="o">==</span> <span class="n">y_flat</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">equals</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'acc :'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">equals</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">logistic_regression</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>loss 0 : [0.9959554]
[0.9287879  0.95044255 0.9990939  0.99938357 0.9999975  0.99999833]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 1 : [0.94137377]
[0.9165606  0.9416799  0.99857545 0.9990305  0.9999944  0.9999962 ]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 2 : [0.8879748]
[0.90264493 0.931614   0.99777395 0.99848396 0.99998736 0.9999914 ]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 3 : [0.8359575]
[0.8869527  0.9201419  0.99654657 0.9976458  0.9999716  0.9999807 ]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 4 : [0.78555274]
[0.8694433  0.9071872  0.9946885  0.996375   0.99993753 0.99995744]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 5 : [0.7370301]
[0.8501429  0.8927156  0.99191684 0.99447495 0.9998648  0.99990785]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 6 : [0.69070476]
[0.82916564 0.87675303 0.9878565  0.9916825  0.9997135  0.99980456]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 7 : [0.6469464]
[0.8067355  0.8594087  0.9820435  0.98766774 0.99940836 0.99959594]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 8 : [0.6061864]
[0.7832069  0.84089863 0.9739604  0.98205316 0.9988166  0.99919075]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
loss 9 : [0.568919]
[0.75907934 0.8215687  0.9631308  0.9744736  0.997724   0.9984414 ]
[1 1 1 1 1 1]
[0 0 1 1 1 1]
[False False  True  True  True  True]
acc : 0.6666666666666666
------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="9_2_logistic_regression_indian">
<a class="anchor" href="#9_2_logistic_regression_indian" aria-hidden="true"><span class="octicon octicon-link"></span></a>9_2_logistic_regression_indian<a class="anchor-link" href="#9_2_logistic_regression_indian"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Q</code> pima-indians-diabetes.csv íŒŒì¼ì„ ì½ì–´ ë‹¹ë‡¨ë³‘ì„ íŒë‹¨í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•˜ì‹œì˜¤</p>
<ul>
<li>ì •í™•ë„ë¥¼ í‘œì‹œí•˜ì‹œì˜¤</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">indian</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'/content/pima-indians-diabetes.csv'</span><span class="p">,</span> <span class="n">skiprows</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">indian</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span> <span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>         <span class="c1">#(768, 8)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">indian</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span> <span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>         <span class="c1">#(768, 1)</span>
       
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(768, 8) (768, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">logistic_regression_indian</span><span class="p">():</span>
  <span class="k">def</span> <span class="nf">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>

  <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>   <span class="c1"># (768, 1) = (768, 8) * (8, 1)</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
      <span class="n">hx</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

      <span class="n">bce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>

    <span class="n">gradient1</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient1</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="s1">':'</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">p_flat</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'acc :'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_flat</span> <span class="o">==</span> <span class="n">y_flat</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">logistic_regression_indian</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>loss 0 : 100.299644
acc : 0.3489583333333333
------------------------------
loss 1 : 90.22592
acc : 0.3489583333333333
------------------------------
loss 2 : 80.1522
acc : 0.3489583333333333
------------------------------
loss 3 : 70.07848
acc : 0.3489583333333333
------------------------------
loss 4 : 60.004757
acc : 0.3489583333333333
------------------------------
loss 5 : 50.08167
acc : 0.3515625
------------------------------
loss 6 : 40.998386
acc : 0.35546875
------------------------------
loss 7 : 33.329323
acc : 0.35546875
------------------------------
loss 8 : 26.595907
acc : 0.3763020833333333
------------------------------
loss 9 : 21.281498
acc : 0.37890625
------------------------------
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="9_3_logistic_regression_indian_split">
<a class="anchor" href="#9_3_logistic_regression_indian_split" aria-hidden="true"><span class="octicon octicon-link"></span></a>9_3_logistic_regression_indian_split<a class="anchor-link" href="#9_3_logistic_regression_indian_split"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>Q</code> 70% ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³  30% ë°ì´í„°ì— ëŒ€í•´ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ì‹œì˜¤</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">logistic_regression_indian</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">dense</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="c1"># (768, 1) = (768, 8) @ (8, 1)</span>
        <span class="c1"># (600, 1) = (600, 8) @ (8, 1)</span>
        <span class="c1"># (168, 1) = (168, 8) @ (8, 1)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span> <span class="o">+</span> <span class="n">b</span>

    <span class="n">indian</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'/content/pima-indians-diabetes.csv'</span><span class="p">,</span> <span class="n">skiprows</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">indian</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span> <span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>         <span class="c1">#(768, 8)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">indian</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span> <span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>         <span class="c1">#(768, 1)</span>
       
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>              <span class="c1"># í‘œì¤€í™”. </span>
    <span class="c1"># x = preprocessing.minmax_scale(x)     # ì •ê·œí™”. </span>
    
    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span>          <span class="c1"># train_size = 600</span>

    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="n">train_size</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">train_size</span><span class="p">:]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">train_size</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_size</span><span class="p">:]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>      <span class="c1"># (537, 8) (231, 8)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>      <span class="c1"># (537, 1) (231, 1)</span>

    <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">dense</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
            <span class="n">hx</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

            <span class="n">bce</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">bce</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">hx</span><span class="p">)</span>

        <span class="n">gradient</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">dense</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="c1"># print(p)</span>

    <span class="n">p_flat</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_flat</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p_flat</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_flat</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'acc :'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_flat</span> <span class="o">==</span> <span class="n">y_flat</span><span class="p">))</span>
    

<span class="n">logistic_regression_indian</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(768, 8) (768, 1)
(537, 8) (231, 8)
(537, 1) (231, 1)
0 0.8600766
10 0.8498678
20 0.83989316
30 0.8301486
40 0.82062995
50 0.8113334
60 0.8022548
70 0.7933905
80 0.78473663
90 0.77628946
100 0.7680453
110 0.76000077
120 0.75215214
130 0.744496
140 0.7370289
150 0.7297474
160 0.7226483
170 0.7157283
180 0.7089841
190 0.70241266
200 0.69601053
210 0.68977475
220 0.6837024
230 0.67779016
240 0.67203516
250 0.6664344
260 0.6609849
270 0.65568364
280 0.65052783
290 0.64551455
300 0.64064085
310 0.63590395
320 0.63130105
330 0.62682927
340 0.62248594
350 0.6182682
360 0.6141733
370 0.61019856
380 0.60634124
390 0.6025988
400 0.5989683
410 0.59544736
420 0.5920332
430 0.5887234
440 0.5855152
450 0.58240604
460 0.5793936
470 0.5764753
480 0.5736487
490 0.5709112
500 0.5682606
510 0.5656945
520 0.56321055
530 0.5608064
540 0.5584798
550 0.55622864
560 0.5540505
570 0.55194336
580 0.54990524
590 0.5479338
600 0.54602724
610 0.5441833
620 0.54240036
630 0.5406763
640 0.53900933
650 0.53739756
660 0.53583926
670 0.5343327
680 0.5328762
690 0.53146803
700 0.5301067
710 0.52879065
720 0.5275183
730 0.52628803
740 0.52509856
750 0.52394855
760 0.5228367
770 0.5217614
780 0.5207217
790 0.51971614
800 0.51874363
810 0.51780313
820 0.5168932
830 0.5160131
840 0.5151616
850 0.51433766
860 0.51354045
870 0.5127689
880 0.51202214
890 0.5112994
900 0.5105997
910 0.50992215
920 0.5092661
930 0.5086309
940 0.50801545
950 0.50741935
960 0.5068418
970 0.5062823
980 0.5057399
990 0.5052143

[0 0 1 1 0 1 0 0 1 1]
[0 0 1 1 1 1 0 0 1 1]
acc : 0.7965367965367965
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="pythonhee/cosmos"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/cosmos/2022/06/30/CNN.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/cosmos/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/cosmos/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/cosmos/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/cosmos/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
